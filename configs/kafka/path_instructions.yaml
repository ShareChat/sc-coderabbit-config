# Apache Kafka Best Practices
- path: "**/{kafka,producer,consumer,broker,topic,stream}*/**"
  instructions: |
    **Comprehensive Kafka Code Review Checklist:**
    
    **ğŸ”§ Client Lifecycle & Resource Management:**
    1. **Singleton Client Pattern:**
       - âœ… Reuse Kafka client instances (Producer, Consumer) throughout application lifecycle
       - âœ… Avoid creating new clients per request/operation
       - âœ… Use dependency injection or singleton patterns for client management
       - âš ï¸ Never create clients inside loops or per-message functions
    
    2. **Connection Management:**
       - âœ… Configure appropriate connection pool settings
       - âœ… Set reasonable connection timeouts and retry policies
       - âœ… Handle connection failures gracefully with exponential backoff
       - âœ… Implement proper client cleanup and shutdown procedures
    
    **ğŸ“¤ Producer Configuration & Best Practices:**
    3. **Performance Tuning:**
       - âœ… Configure `MaxBatchBytes` for optimal batch sizes (e.g., 16KB-1MB)
       - âœ… Set `MaxBufferedRecords` to control memory usage
       - âœ… Use `ProducerLinger` to balance latency vs throughput
       - âœ… Configure `RecordRetries` for failed message handling (typically 3-5)
       - âœ… Set `ProduceRequestTimeout` to prevent indefinite hangs
    
    4. **Reliability & Consistency:**
       - âœ… Enable idempotent producers (`enable.idempotence=true`) to prevent duplicates
       - âœ… Configure `RequiredAcks` based on durability needs:
         - `LeaderAck` for high throughput, lower durability
         - `AllISRAcks` for highest durability, lower throughput
       - âœ… Implement proper error handling for different failure scenarios
    
    5. **Batching & Compression:**
       - âœ… Enable compression (Gzip, Snappy, LZ4, Zstd) for network efficiency
       - âœ… Tune `batch.size` and `linger.ms` for optimal compression ratios
       - âœ… Ensure `max.request.size` accommodates your batch sizes
    
    **ğŸ“¥ Consumer Configuration & Best Practices:**
    6. **Performance & Efficiency:**
       - âœ… Configure `FetchMinBytes` and `FetchMaxBytes` for optimal throughput
       - âœ… Set `MaxConcurrentFetches` based on available resources
       - âœ… Use appropriate `SessionTimeout` and `RebalanceTimeout` values
       - âœ… Configure `HeartbeatInterval` for stable consumer group membership
    
    7. **Offset Management:**
       - âœ… Use `enable.auto.commit=false` for manual control when needed
       - âœ… Handle offset commit failures gracefully
       - âœ… Implement offset reset strategies for consumer group scenarios
       - âœ… Monitor consumer lag and implement alerting
    
    8. **Consumer Group Management:**
       - âœ… Ensure consumers are part of a consumer group
       - âœ… Handle rebalancing events properly
       - âœ… Implement graceful shutdown procedures
       - âœ… Monitor consumer group health and stability
    
    **ğŸ›¡ï¸ Security & Best Practices:**
    9. **Authentication & Authorization:**
       - âœ… Use secure credential management (not hardcoded)
    
    10. **Data Security:**
        - âœ… Use encryption for sensitive data in transit
        - âœ… Implement proper key management for encrypted topics
        - âœ… Audit access patterns and implement monitoring
        - âœ… Follow principle of least privilege for topic access
    
    **ğŸ“Š Error Handling & Resilience:**
    11. **Error Classification & Handling:**
        - âœ… Distinguish between transient and permanent errors
        - âœ… Implement retry logic with exponential backoff for transient errors
        - âœ… Handle permanent errors gracefully (log, alert, circuit break)
        - âœ… Implement dead letter queues for failed messages
        - âœ… Monitor error rates and implement alerting
    
    12. **Circuit Breaker Patterns:**
        - âœ… Implement circuit breakers for broker failures
        - âœ… Monitor circuit breaker state and metrics
        - âœ… Implement fallback mechanisms when possible
    
    **ğŸ“ˆ Observability & Monitoring:**
    13. **Metrics & Monitoring:**
        - âœ… Track producer/consumer throughput and latency
        - âœ… Monitor consumer lag and offset commit success rates
        - âœ… Track error rates and failure patterns
        - âœ… Monitor connection pool utilization and health
        - âœ… Implement health checks for Kafka clients
    
    14. **Logging & Tracing:**
        - âœ… Log important operations (produce/consume, errors, rebalances)
        - âœ… Include correlation IDs for request tracing
        - âœ… Log configuration changes and client lifecycle events
        - âœ… Use structured logging with consistent field names
    
    **ğŸš¨ Common Anti-Patterns to Flag:**
    - âŒ Creating new Kafka clients per operation
    - âŒ Missing error handling for network failures
    - âŒ No retry logic for transient errors
    - âŒ Missing timeout configurations
    - âŒ Hardcoded broker addresses or credentials
    - âŒ No monitoring or metrics implementation
    - âŒ Missing consumer group configuration
    - âŒ No offset commit error handling
    - âŒ Disabled idempotence without justification
    - âŒ No compression enabled for producers
    
    **ğŸ” Review Focus Areas:**
    - Verify client lifecycle management and reuse patterns
    - Check producer/consumer configuration for optimal settings
    - Ensure proper error handling and retry logic
    - Validate security configurations and authentication
    - Review offset management and consumer group handling
    - Check for monitoring and observability implementation
    - Identify opportunities for Prometheus metrics
    
    **ğŸ“Š Prometheus Metrics Opportunities:**
    - ğŸ” **Automatically suggest metrics when seeing:**
      - Kafka producers â†’ `kafka_producer_messages_total{topic, status}`
      - Kafka consumers â†’ `kafka_consumer_messages_total{topic, partition}`
      - Message processing â†’ `kafka_message_duration_seconds{topic, operation}`
      - Error handling â†’ `kafka_errors_total{type, topic, operation}`
      - Consumer lag â†’ `kafka_consumer_lag{topic, partition, group}`
      - Connection health â†’ `kafka_connection_status{broker, state}`
      - Offset commits â†’ `kafka_offset_commits_total{topic, group, status}`
